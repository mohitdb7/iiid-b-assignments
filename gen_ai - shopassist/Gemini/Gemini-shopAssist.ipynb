{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b162f3a6-8a96-4f7d-9248-f47be2ecace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f44ab6-8623-4298-9fd6-f1afec576540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54543b6f-29d3-4142-a92c-432aefe6d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a99d60-3f83-4b25-85cb-a82a032e48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "import re\n",
    "import ast\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "661e1b06-d558-4db3-a607-5e17c480b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc11f5c-515a-46eb-bff3-5492803122df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Core</th>\n",
       "      <th>CPU Manufacturer</th>\n",
       "      <th>Clock Speed</th>\n",
       "      <th>RAM Size</th>\n",
       "      <th>Storage Type</th>\n",
       "      <th>Display Type</th>\n",
       "      <th>Display Size</th>\n",
       "      <th>Graphics Processor</th>\n",
       "      <th>Screen Resolution</th>\n",
       "      <th>OS</th>\n",
       "      <th>Laptop Weight</th>\n",
       "      <th>Special Features</th>\n",
       "      <th>Warranty</th>\n",
       "      <th>Average Battery Life</th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell</td>\n",
       "      <td>Inspiron</td>\n",
       "      <td>i5</td>\n",
       "      <td>Intel</td>\n",
       "      <td>2.4 GHz</td>\n",
       "      <td>8GB</td>\n",
       "      <td>SSD</td>\n",
       "      <td>LCD</td>\n",
       "      <td>15.6\"</td>\n",
       "      <td>Intel UHD</td>\n",
       "      <td>1920x1080</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>2.5 kg</td>\n",
       "      <td>Backlit Keyboard</td>\n",
       "      <td>1 year</td>\n",
       "      <td>6 hours</td>\n",
       "      <td>35,000</td>\n",
       "      <td>The Dell Inspiron is a versatile laptop that c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSI</td>\n",
       "      <td>GL65</td>\n",
       "      <td>i7</td>\n",
       "      <td>Intel</td>\n",
       "      <td>2.6 GHz</td>\n",
       "      <td>16GB</td>\n",
       "      <td>HDD+SSD</td>\n",
       "      <td>IPS</td>\n",
       "      <td>15.6\"</td>\n",
       "      <td>NVIDIA GTX</td>\n",
       "      <td>1920x1080</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>2.3 kg</td>\n",
       "      <td>RGB Keyboard</td>\n",
       "      <td>2 years</td>\n",
       "      <td>4 hours</td>\n",
       "      <td>55,000</td>\n",
       "      <td>The MSI GL65 is a high-performance laptop desi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP</td>\n",
       "      <td>EliteBook</td>\n",
       "      <td>i7</td>\n",
       "      <td>Intel</td>\n",
       "      <td>2.8 GHz</td>\n",
       "      <td>16GB</td>\n",
       "      <td>SSD</td>\n",
       "      <td>LED</td>\n",
       "      <td>14\"</td>\n",
       "      <td>Intel UHD</td>\n",
       "      <td>1920x1080</td>\n",
       "      <td>Windows 11</td>\n",
       "      <td>1.5 kg</td>\n",
       "      <td>Fingerprint Sensor</td>\n",
       "      <td>3 years</td>\n",
       "      <td>8 hours</td>\n",
       "      <td>90,000</td>\n",
       "      <td>The HP EliteBook is a premium laptop designed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo</td>\n",
       "      <td>IdeaPad</td>\n",
       "      <td>i3</td>\n",
       "      <td>Intel</td>\n",
       "      <td>2.1 GHz</td>\n",
       "      <td>8GB</td>\n",
       "      <td>HDD</td>\n",
       "      <td>TN</td>\n",
       "      <td>15.6\"</td>\n",
       "      <td>Intel UHD</td>\n",
       "      <td>1366x768</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>2.2 kg</td>\n",
       "      <td>Dolby Audio</td>\n",
       "      <td>1 year</td>\n",
       "      <td>5 hours</td>\n",
       "      <td>25,000</td>\n",
       "      <td>The Lenovo IdeaPad is a versatile laptop that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ZenBook Pro</td>\n",
       "      <td>i9</td>\n",
       "      <td>Intel</td>\n",
       "      <td>3.1 GHz</td>\n",
       "      <td>64GB</td>\n",
       "      <td>SSD</td>\n",
       "      <td>OLED</td>\n",
       "      <td>15.6\"</td>\n",
       "      <td>NVIDIA RTX</td>\n",
       "      <td>3840x2160</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>1.8 kg</td>\n",
       "      <td>NanoEdge Display</td>\n",
       "      <td>2 years</td>\n",
       "      <td>7 hours</td>\n",
       "      <td>200,000</td>\n",
       "      <td>The ASUS ZenBook Pro is a high-end laptop that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Brand   Model Name Core CPU Manufacturer Clock Speed RAM Size Storage Type Display Type  \\\n",
       "0    Dell     Inspiron   i5            Intel     2.4 GHz      8GB          SSD          LCD   \n",
       "1     MSI         GL65   i7            Intel     2.6 GHz     16GB      HDD+SSD          IPS   \n",
       "2      HP    EliteBook   i7            Intel     2.8 GHz     16GB          SSD          LED   \n",
       "3  Lenovo      IdeaPad   i3            Intel     2.1 GHz      8GB          HDD           TN   \n",
       "4    ASUS  ZenBook Pro   i9            Intel     3.1 GHz     64GB          SSD         OLED   \n",
       "\n",
       "  Display Size Graphics Processor Screen Resolution          OS Laptop Weight    Special Features  \\\n",
       "0        15.6\"          Intel UHD         1920x1080  Windows 10        2.5 kg    Backlit Keyboard   \n",
       "1        15.6\"         NVIDIA GTX         1920x1080  Windows 10        2.3 kg        RGB Keyboard   \n",
       "2          14\"          Intel UHD         1920x1080  Windows 11        1.5 kg  Fingerprint Sensor   \n",
       "3        15.6\"          Intel UHD          1366x768  Windows 10        2.2 kg         Dolby Audio   \n",
       "4        15.6\"         NVIDIA RTX         3840x2160  Windows 10        1.8 kg    NanoEdge Display   \n",
       "\n",
       "  Warranty Average Battery Life    Price                                        Description  \n",
       "0   1 year              6 hours   35,000  The Dell Inspiron is a versatile laptop that c...  \n",
       "1  2 years              4 hours   55,000  The MSI GL65 is a high-performance laptop desi...  \n",
       "2  3 years              8 hours   90,000  The HP EliteBook is a premium laptop designed ...  \n",
       "3   1 year              5 hours   25,000  The Lenovo IdeaPad is a versatile laptop that ...  \n",
       "4  2 years              7 hours  200,000  The ASUS ZenBook Pro is a high-end laptop that...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the display width to control the output width\n",
    "pd.set_option('display.width', 100)\n",
    "# Read the dataset and read the Laptop Dataset\n",
    "df = pd.read_csv('../laptop_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b4ab9b-f970-413a-b040-c01d8ec33c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 18 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Brand                 20 non-null     object\n",
      " 1   Model Name            20 non-null     object\n",
      " 2   Core                  20 non-null     object\n",
      " 3   CPU Manufacturer      20 non-null     object\n",
      " 4   Clock Speed           20 non-null     object\n",
      " 5   RAM Size              20 non-null     object\n",
      " 6   Storage Type          20 non-null     object\n",
      " 7   Display Type          20 non-null     object\n",
      " 8   Display Size          20 non-null     object\n",
      " 9   Graphics Processor    20 non-null     object\n",
      " 10  Screen Resolution     20 non-null     object\n",
      " 11  OS                    20 non-null     object\n",
      " 12  Laptop Weight         20 non-null     object\n",
      " 13  Special Features      20 non-null     object\n",
      " 14  Warranty              20 non-null     object\n",
      " 15  Average Battery Life  20 non-null     object\n",
      " 16  Price                 20 non-null     object\n",
      " 17  Description           20 non-null     object\n",
      "dtypes: object(18)\n",
      "memory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ba0d507-b1e5-4af5-8fa4-54c14452b5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     The Dell Inspiron is a versatile laptop that c...\n",
       "1     The MSI GL65 is a high-performance laptop desi...\n",
       "2     The HP EliteBook is a premium laptop designed ...\n",
       "3     The Lenovo IdeaPad is a versatile laptop that ...\n",
       "4     The ASUS ZenBook Pro is a high-end laptop that...\n",
       "5     The Acer Predator is a powerhouse laptop desig...\n",
       "6     The Microsoft Surface Laptop is a premium devi...\n",
       "7     The Lenovo ThinkPad is a powerful laptop desig...\n",
       "8     The HP Pavilion is a budget-friendly laptop th...\n",
       "9     The ASUS ROG Strix G is a high-performance gam...\n",
       "10    The Dell XPS 15 is a premium laptop that combi...\n",
       "11    The Lenovo ThinkPad X1 Carbon is a sleek and l...\n",
       "12    The Acer Swift 3 is a lightweight and affordab...\n",
       "13    The Apple MacBook Air is a sleek and lightweig...\n",
       "14    The MSI Prestige 14 is a compact and stylish l...\n",
       "15    The ASUS ZenBook 13 is a lightweight and power...\n",
       "16    The Dell Precision 5550 is a high-performance ...\n",
       "17    The HP ENVY x360 is a versatile 2-in-1 convert...\n",
       "18    The Razer Blade 15 is a high-performance gamin...\n",
       "19    The Apple MacBook Pro is a high-end laptop tha...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3940c5bb-34fb-43e3-87d3-ad8be09001a4",
   "metadata": {},
   "source": [
    "<img src=\"../stage_system_design.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509eabd8-b2bb-4f7e-8aa8-dc9b2301002d",
   "metadata": {},
   "source": [
    "# Stage 1: Intent Clarity and Intent Confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e53ac-7b46-49d5-b458-93e0c843c2b8",
   "metadata": {},
   "source": [
    "<img src=\"../image+3.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e2e778a-c679-491d-9086-3230db9d7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = open(\"gemini_API_Key.txt\", \"r\").read().strip()\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39024f43-87cb-406f-9af5-3511d3f1064d",
   "metadata": {},
   "source": [
    "## Step1: Initialise the conversation with base prompt\n",
    "- Role of the model\n",
    "- Guidelines for the model\n",
    "- Instruction within the transcripts\n",
    "- Chain of Thoughts\n",
    "- Few Shot examples (samples)\n",
    "\n",
    "- Returns a list [{\"role\": \"model\", \"parts\": [system_message]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e07630c8-9a6d-4f11-9fab-ec124be98351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_conversation():\n",
    "    delimiter = \"####\"\n",
    "\n",
    "    example_user_dict = {'GPU intensity': \"high\",\n",
    "                        'Display quality':\"high\",\n",
    "                        'Portability': \"low\",\n",
    "                        'Multitasking': \"high\",\n",
    "                        'Processing speed': \"high\",\n",
    "                        'Budget': \"150000\"}\n",
    "\n",
    "    example_user_req = {'GPU intensity': \"_\",\n",
    "                        'Display quality': \"_\",\n",
    "                        'Portability': \"_\",\n",
    "                        'Multitasking': \"_\",\n",
    "                        'Processing speed': \"_\",\n",
    "                        'Budget': \"_\"}\n",
    "\n",
    "    system_message = open(\"../Prompts/initialize_conversation.txt\", \"r\").read().strip().format(delimiter=delimiter, \n",
    "                                                                           example_user_dict=example_user_dict, \n",
    "                                                                           example_user_req=example_user_req)\n",
    "    conversation = [{\"role\": \"model\", \"parts\": [system_message]}]\n",
    "    # conversation = system_message\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3132d7-3bdb-4b62-867c-63b05866cabd",
   "metadata": {},
   "source": [
    "#### Displaying the base prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547ec51-3f0f-4457-8974-ba276d928fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_conversation = initialize_conversation()\n",
    "print(debug_conversation[0]['parts'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73d539-d0f6-469f-a2d6-800b64a41861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b130477-2194-47f1-9ee6-bd339c9c9eef",
   "metadata": {},
   "source": [
    "#### Moderation on user input does not work in Gemini. \n",
    "The API is not publicly available. \n",
    "It can only provide safety ratings on generated response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d0168-afba-4dcf-bac8-ab7bb9c8968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moderation does not work well with Gemini\n",
    "def moderation_check(user_input):\n",
    "    MODEL = 'gemini-1.5-flash'\n",
    "    model = genai.GenerativeModel(MODEL)\n",
    "    response = model.generate_content(user_input, safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    })\n",
    "\n",
    "    print(response)\n",
    "    # for rating in response.candidates[0].safety_ratings:\n",
    "        # if rating.HarmProbability > HarmCategory.:\n",
    "        #     return False\n",
    "\n",
    "    # return True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83306a2-12dc-40e8-891a-b7cdc931a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "moderation_check(\"I want to kill them\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85edbbd6-3bbd-4b53-a844-dd9261a113ec",
   "metadata": {},
   "source": [
    "### `get_chat_completions` - Define the function get_chat_completions with two parameters\n",
    "- prompt\n",
    "- Is Json response type\n",
    "\n",
    "The prompt this time will contain the user query as well\n",
    "- If json response type then we will return a json\n",
    "- Else, we will return text result\n",
    "\n",
    "`@retry` - In case of failure, retry up to 6 times with exponential backoff, starting at 1 second and maxing out at 20 seconds delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "296f1ae0-ad79-40f6-806b-55c24153a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Chat Completions API call\n",
    "# Retry up to 6 times with exponential backoff, starting at 1 second and maxing out at 20 seconds delay\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def get_chat_completions(input, json_format = False):\n",
    "    MODEL = 'gemini-1.5-flash'\n",
    "\n",
    "    system_message_json_output = \"\"\"<<. Return output in JSON format to the key output.>>\"\"\"\n",
    "    gemini_model = genai.GenerativeModel(MODEL)\n",
    "    # Only 1 candidate_count is allowed as of now\n",
    "    if json_format:\n",
    "        gen_config = genai.types.GenerationConfig(candidate_count=1,\n",
    "                                              temperature=0, \n",
    "                                              response_mime_type=\"application/json\")\n",
    "        chat_completion_json = gemini_model.generate_content(input, \n",
    "                                           generation_config=gen_config)\n",
    "\n",
    "        output = json.loads(chat_completion_json.candidates[0].content.parts[0].text)\n",
    "        return output\n",
    "    else:\n",
    "        gen_config = genai.types.GenerationConfig(candidate_count=1,\n",
    "                                              temperature=0)\n",
    "        chat_completion_json = gemini_model.generate_content(input, \n",
    "                                           generation_config=gen_config)\n",
    "\n",
    "        output = chat_completion_json.candidates[0].content.parts[0].text\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e55be-bbd1-428c-a4da-cbc6d42c71fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the OpenAI functions defined above\n",
    "input_prompt ='What is the capital of France?'\n",
    "messages = [{'role':'user','parts':[input_prompt]}]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47235261-0329-402c-ac5c-0dbf480bd2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_chat_completions(messages), get_chat_completions(messages, json_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ecf75e-9428-44f9-9ee3-301006c341d0",
   "metadata": {},
   "source": [
    "### `iterate_llm_response` - Iterate the same prompt for `n` number of times and verify the consistency of the result\n",
    "\n",
    "Calls a specified function repeatedly and prints the results.\n",
    "This function is designed to test the consistency of a response from a given function.\n",
    "It calls the function multiple times (default is 10) and prints out the iteration count,\n",
    "the function's response(s).<br/>\n",
    "\n",
    "Args:\n",
    "- funct (function): The function to be tested. This function should accept a single argument\n",
    "                  and return the response value(s).\n",
    "- debug_response (dict): The input argument to be passed to 'funct' on each call.\n",
    "- num (int, optional): The number of times 'funct' will be called. Defaults to 10.\n",
    "\n",
    "Returns:\n",
    "    This function only returns the results to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "481bbb1e-22fb-4f10-a652-df8d7658786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_llm_response(funct, debug_response, num = 10):\n",
    "    i = 0  # Initialize counter\n",
    "\n",
    "    while i < num:  # Loop to call the function 'num' times\n",
    "\n",
    "        response = funct(debug_response)  # Call the function with the debug response\n",
    "\n",
    "        # Print the iteration number, result, and reason from the response\n",
    "        print(\"Iteration: {0}\".format(i))\n",
    "        print(response)\n",
    "        print('-' * 50)  # Print a separator line for readability\n",
    "        i += 1  # Increment the counter\n",
    "\n",
    "# Example usage: test the consistency of responses from 'intent_confirmation_layer'\n",
    "# iterate_llm_response(get_chat_completions, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8748a5a1-3500-4018-9185-eb6d0f7ecc62",
   "metadata": {},
   "source": [
    "## Step2: Initialise the user query in the base prompt\n",
    "- Initialise user query in base prompt\n",
    "- Send it to the model to evaluate\n",
    "- Model will return text output or json output based on the parameter sent to `get_chat_completion` function\n",
    "- Add system response to the base prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a69d698-db59-478a-a562-b488b1631fcd",
   "metadata": {},
   "source": [
    "#### Initialise user query in base prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b0e6e-f63f-4ef7-a065-34161ad62a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_user_input = \"Hi, I am Anand. I need a laptop for coding.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b04abc-77fc-4ba7-a977-8795d9d894a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_conversation.append({\"role\": \"user\", \"parts\": [debug_user_input]})\n",
    "print(debug_conversation[1][\"parts\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d0270-08f7-44cf-8f8a-d9c63b1d6181",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(debug_conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371ad0a7-95a0-4116-8971-096b90cba5e6",
   "metadata": {},
   "source": [
    "#### Send it to the model to evaluate - Text response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2258f71d-5e97-4027-892b-2400a277d802",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_response_assistant = get_chat_completions(debug_conversation)\n",
    "print(debug_response_assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b703294-0ef4-443a-b225-5194717fc52a",
   "metadata": {},
   "source": [
    "#### Send it to the model to evaluate - Json response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed1096-f28c-47c1-9e8e-e79530ab00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_response_assistant_json = get_chat_completions(debug_conversation, json_format=True)\n",
    "print(debug_response_assistant_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38455ac2-8dbc-4981-9eb1-4fc12250fef7",
   "metadata": {},
   "source": [
    "#### Add system response to the base prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e93d13f-c632-4b02-a1cc-35df4a2c339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_conversation.append({\"role\": \"model\", \"parts\": [debug_response_assistant]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8419c8-e2eb-4595-9da9-b4df05692d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(debug_conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce49fe-a0f3-419e-a49f-bffc8a555e00",
   "metadata": {},
   "source": [
    "### intent_confirmation_layer()\n",
    "This function takes the assistant's response and evaluates if the chatbot has captured the user's profile clearly. Specifically, this checks \n",
    "\n",
    "    Parameters:\n",
    "    - response_assistant (str): The input text containing user requirements captured through 6 keys:\n",
    "        'GPU intensity', 'Display quality', 'Portability', 'Multitasking', 'Processing speed', and 'Budget'.\n",
    "\n",
    "    Returns:\n",
    "    - str: A one-word string in JSON format indicating if the values for the specified keys are correctly filled.\n",
    "        - 'Yes' if the values are correctly filled for all keys ('GPU intensity', 'Display quality', 'Portability',\n",
    "          'Multitasking', 'Processing speed') based on the importance as stated by the user.\n",
    "        - 'No' otherwise.\n",
    "\n",
    "    Note:\n",
    "    - The values for all keys, except 'Budget', should be 'low', 'medium', or 'high' based on their importance as stated by the user.\n",
    "    - The input text should be structured such that it contains the necessary keys and their corresponding values.\n",
    "    - The function uses OpenAI's Chat Completion API to evaluate the correctness of the input values.\n",
    "\n",
    "if the following properties for the user has been captured or not\n",
    "   - GPU intensity\n",
    "   - Display quality\n",
    "   - Portability\n",
    "   - Multitasking\n",
    "   - Processing speed\n",
    "   - Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cc5f57b-46f4-42be-be1e-59f275e16f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intent_confirmation_layer(response_assistant):\n",
    "    MODEL = 'gemini-1.5-flash'\n",
    "    gemini_model = genai.GenerativeModel(MODEL)\n",
    "    \n",
    "    delimiter = \"####\"\n",
    "    allowed_values = {'low','medium','high'}\n",
    "    \n",
    "    prompt = open(\"../Prompts/intent_confirmation_layer.txt\", \"r\").read().strip().format(allowed_values=allowed_values, \n",
    "                                                                                         delimiter=delimiter)\n",
    "    messages=[{\"role\": \"model\", \"parts\":[prompt] },\n",
    "              {\"role\": \"user\", \"parts\":[f\"\"\"Here is the input: {response_assistant}\"\"\"]}]\n",
    "\n",
    "    gen_config = genai.types.GenerationConfig(candidate_count=1,\n",
    "                                              temperature=0, \n",
    "                                              response_mime_type=\"application/json\")\n",
    "    intent_confirmation_json = gemini_model.generate_content(messages, \n",
    "                                       generation_config=gen_config)\n",
    "\n",
    "    output = json.loads(intent_confirmation_json.candidates[0].content.parts[0].text)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21403ee7-71b0-4ad0-b73c-1f55dfac928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(debug_response_assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a04d0-ae78-4a2c-b6b2-0997aa17bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_confirmation = intent_confirmation_layer(debug_response_assistant)\n",
    "display(debug_confirmation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4553dba-83e1-47bd-a910-f0a8c42893f8",
   "metadata": {},
   "source": [
    "#### Extract the dictionary from the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffcdaf7d-b183-4bde-88fa-462a35050dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_present(response):\n",
    "    delimiter = \"####\"\n",
    "\n",
    "    user_req = {'GPU intensity': 'high',\n",
    "                'Display quality': 'high',\n",
    "                'Portability': 'medium',\n",
    "                'Multitasking': 'high',\n",
    "                'Processing speed': 'high',\n",
    "                'Budget': '200000'}\n",
    "\n",
    "    prompt = open(\"../Prompts/dictionary_present.txt\", \"r\").read().strip().format(delimiter=delimiter, \n",
    "                                                                                        user_req=user_req)\n",
    "    messages = [{\"role\": \"model\", \"parts\":[prompt]},\n",
    "                {\"role\": \"user\", \"parts\":[f\"\"\"Here is the user input: {response}\"\"\" ]}]\n",
    "\n",
    "    confirmation = get_chat_completions(messages, json_format = True)\n",
    "\n",
    "    return confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247393a7-ac8f-4eaf-bad6-cb58816ffbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_response_assistant_n = f\"\"\"Thank you for providing your budget.\n",
    "Based on your budget of 80,000 INR, I will consider this while recommending suitable laptop options for you.\n",
    "Here is the final recommendation for your laptop:\n",
    "- GPU intensity: high\n",
    "- Display quality: high\n",
    "- Portability: low\n",
    "- Multitasking: high\n",
    "- Processing speed: medium\n",
    "- Budget: 80,000 INR\n",
    "\n",
    "Please note that these specifications are based on your requirements for surfing and a decent display within your budget.\n",
    "Let me know if there's anything else I can assist you with!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a0f3c-3ebb-457c-93eb-f41cd273a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate_llm_response(dictionary_present, debug_response_assistant_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3dd463-4ffe-4095-b6b2-c0f862a4cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_conversation = initialize_conversation()\n",
    "debug_user_input = \"Hi, I am Anand. I need a laptop for coding.\"\n",
    "# debug_moderation = moderation_check(debug_user_input)\n",
    "debug_conversation.append({\"role\": \"user\", \"parts\": [debug_user_input]})\n",
    "debug_response_assistant = get_chat_completions(debug_conversation)\n",
    "# debug_moderation = moderation_check(debug_response_assistant)\n",
    "debug_conversation.append({\"role\": \"model\", \"parts\": [debug_response_assistant]})\n",
    "debug_confirmation = intent_confirmation_layer(debug_response_assistant)\n",
    "# After a series of conversation...\n",
    "response_dict_n = dictionary_present(debug_response_assistant_n)\n",
    "print(response_dict_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8022db6-cbb9-44c3-9e23-9852700236ea",
   "metadata": {},
   "source": [
    "# Stage 2: Product Extraction and Product Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c7d89-470d-4c22-b459-34a8e7062464",
   "metadata": {},
   "source": [
    "<img src=\"../Stage+2.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db8f860-1b6c-4582-b477-24ba4fbcc6ec",
   "metadata": {},
   "source": [
    "### product_map_layer()\n",
    "This function is responsible for extracting key features and criteria from laptop descriptions. Here's a breakdown of how it works:\n",
    "-  Use a prompt that assign it the role of a Laptop Specifications Classifier, whose objective is to extract key features and classify them based on laptop descriptions.\n",
    "- Provide step-by-step instructions for extracting laptop features from description.\n",
    "- Assign specific rules for each feature (e.g., GPU Intensity, Display Quality, Portability, Multitasking, Processing Speed) and associate them with the appropriate classification value (Low, Medium, or High).\n",
    "- Includes Few Shot Prompting (sample conversation between the user and assistant) to demonstrate the expected result of the feature extraction and classification process.\n",
    "\n",
    "#### Extracts key features from a laptop description and classifies them based on predefined rules.\n",
    "- Args: laptop_description (str): The description of the laptop to be analyzed.\n",
    "- Returns:\n",
    "        - dict: A dictionary containing the classified features of the laptop.\n",
    "            Keys represent different aspects such as GPU intensity, Display quality, Portability,\n",
    "            Multitasking, and Processing speed, each mapped to a value indicating the classification\n",
    "            (low, medium, or high) based on the extracted feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa59930e-021c-404e-af5e-09f1b979bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_map_layer(laptop_description):\n",
    "    delimiter = \"#####\"\n",
    "    lap_spec = {\n",
    "        \"GPU intensity\":\"(Type of the Graphics Processor)\",\n",
    "        \"Display quality\":\"(Screen Resolution)\",\n",
    "        \"Portability\":\"(Laptop Weight)\",\n",
    "        \"Multitasking\":\"(RAM)\",\n",
    "        \"Processing speed\":\"(CPU Manufacturer, Core)\"\n",
    "    }\n",
    "    values = {'low','medium','high'}\n",
    "\n",
    "    prompt = open(\"../Prompts/product_map_layer.txt\", \"r\").read().strip().format(delimiter=delimiter, \n",
    "                                                                                 lap_spec=lap_spec, \n",
    "                                                                                 values=values,\n",
    "                                                                                 laptop_description=laptop_description)\n",
    "\n",
    "    input = f\"\"\"Follow the prompt instructions step-by-step and output the dictionary in JSON format for the following laptop {laptop_description}.\"\"\"\n",
    "\n",
    "    messages=[{\"role\": \"model\", \"parts\":[prompt]},{\"role\": \"user\",\"parts\":[input]}]\n",
    "\n",
    "    response = get_chat_completions(messages)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0431f03-12bc-443c-be4a-f7905b0c9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_laptop_description = f\"\"\"\n",
    "The Dell Inspiron is a versatile laptop that combines powerful performance and affordability.\n",
    "It features an Intel Core i5 processor clocked at 2.4 GHz, ensuring smooth multitasking and efficient computing.\n",
    "With 8GB of RAM and an SSD, it offers quick data access and ample storage capacity.\n",
    "The laptop sports a vibrant 15.6\" LCD display with a resolution of 1920x1080, delivering crisp visuals and immersive viewing experience.\n",
    "Weighing just 2.5 kg, it is highly portable, making it ideal for on-the-go usage.\n",
    "Additionally, it boasts an Intel UHD GPU for decent graphical performance and a backlit keyboard for enhanced typing convenience.\n",
    "With a one-year warranty and a battery life of up to 6 hours, the Dell Inspiron is a reliable companion for work or entertainment.\n",
    "All these features are packed at an affordable price of 35,000, making it an excellent choice for budget-conscious users.\n",
    "\"\"\"\n",
    "display(product_map_layer(debug_laptop_description))\n",
    "print(type(product_map_layer(debug_laptop_description)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3807b-6f4b-45d8-92be-de004c03d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate_llm_response(product_map_layer, debug_laptop_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88200d07-dfca-414e-8633-56e91c2c2cbe",
   "metadata": {},
   "source": [
    "### Update the Laptop CSV with the Laptop Feature\n",
    "- Read each row of the Laptop database and apply product_map_layer\n",
    "- This will provide a dictionary, store it in laptop feature function\n",
    "- Use this new column for comparing with User requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fad51ab7-a57c-4e89-9093-948121f7ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dictionary_with_wait(columnSeries, isDebug):\n",
    "    updated_features = []\n",
    "    for item in columnSeries:\n",
    "        time.sleep(10)\n",
    "        result = product_map_layer(item)\n",
    "        updated_features.append(result)\n",
    "        if isDebug:\n",
    "            print(result)\n",
    "    return updated_features\n",
    "    \n",
    "def update_laptop_csv_with_feature(isDebug = False):\n",
    "    laptop_csv = pd.read_csv(\"../laptop_data.csv\")\n",
    "    updated_features = generate_dictionary_with_wait(laptop_csv[\"Description\"], isDebug=isDebug)\n",
    "    laptop_csv[\"laptop_feature\"] = updated_features\n",
    "    laptop_csv.to_csv(\"../updated_laptop_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b8cfc6-3a04-4866-a2f1-3c5497ae1068",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_laptop_csv_with_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95668d-eff6-46d8-aa6b-b9f9efd4b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_laptop_csv = pd.read_csv(\"../updated_laptop_data.csv\")\n",
    "updated_laptop_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c9efc0f-a7c9-47fc-be9a-5f00679a5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dictionary_from_string(string):\n",
    "    regex_pattern = r\"\\{[^{}]+\\}\"\n",
    "\n",
    "\n",
    "    dictionary_matches = re.findall(regex_pattern, string)\n",
    "\n",
    "\n",
    "    # Extract the first dictionary match and convert it to lowercase\n",
    "    if dictionary_matches:\n",
    "        dictionary_string = dictionary_matches[0]\n",
    "        dictionary_string = dictionary_string.lower()\n",
    "\n",
    "\n",
    "        # Convert the dictionary string to a dictionary object using ast.literal_eval()\n",
    "        dictionary = ast.literal_eval(dictionary_string)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3be6ac2-4b7f-4318-86cf-085e1ecc7587",
   "metadata": {},
   "source": [
    "### compare_laptops_with_user()\n",
    "This function compares the user's profile with the different laptops and come back with the top  recommendations. It will perform the following steps:\n",
    "    - It will take the user requirements dictionary as input\n",
    "    - Filter the laptops based on their price, keeping only the ones within the user's budget.\n",
    "    - Calculate a score for each laptop based on how well it matches the user's requirements.\n",
    "    - Sort the laptops based on their scores in descending order.\n",
    "    - Return the top 3 laptops as a JSON-formatted string.\n",
    "\n",
    "#### Compares laptops based on user requirements and returns the top 3 matching laptops in JSON format.\n",
    "\n",
    "    Parameters:\n",
    "    - user_req_string (str): A string representing user requirements in JSON format.\n",
    "\n",
    "    Returns:\n",
    "    - str: A JSON string containing information about the top 3 matching laptops based on user requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a71c153-f92c-4d2a-8edd-679fbf489a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_budget_in_int(requirements_dic):\n",
    "    return requirements_dic.get('budget'.capitalize(), '0') if type(requirements_dic.get('budget'.capitalize(), '0')) == int else int(requirements_dic.get('budget'.capitalize(), '0').replace(',', '').split()[0])\n",
    "    \n",
    "def compare_laptops_with_user(user_req_string):\n",
    "    laptop_df= pd.read_csv('../updated_laptop_data.csv')\n",
    "    user_requirements = user_req_string if type(user_req_string) == dict else extract_dictionary_from_string(user_req_string)\n",
    "    budget =  get_budget_in_int(user_requirements)\n",
    "\n",
    "    filtered_laptops = laptop_df.copy()\n",
    "    filtered_laptops[\"Price\"] = filtered_laptops[\"Price\"].str.replace(',', '').astype(int)\n",
    "    filtered_laptops = filtered_laptops[filtered_laptops[\"Price\"] <= budget].copy()\n",
    "    \n",
    "    mappings = {\n",
    "        'low': 0,\n",
    "        'medium': 1,\n",
    "        'high': 2\n",
    "    }\n",
    "    # Create 'Score' column in the DataFrame and initialize to 0\n",
    "    filtered_laptops['Score'] = 0\n",
    "    for index, row in filtered_laptops.iterrows():\n",
    "        user_product_match_str = row['laptop_feature']\n",
    "        laptop_values = extract_dictionary_from_string(user_product_match_str)\n",
    "        score = 0\n",
    "\n",
    "\n",
    "        for key, user_value in user_requirements.items():\n",
    "            if key.lower() == 'budget':\n",
    "                continue  # Skip budget comparison\n",
    "            laptop_value = laptop_values.get(key.lower(), None)\n",
    "            laptop_mapping = mappings.get(laptop_value.lower(), -1)\n",
    "            user_mapping = mappings.get(user_value.lower(), -1)\n",
    "            if laptop_mapping >= user_mapping:\n",
    "                ### If the laptop value is greater than or equal to the user value the score is incremented by 1\n",
    "                score += 1\n",
    "\n",
    "\n",
    "        filtered_laptops.loc[index, 'Score'] = score\n",
    "\n",
    "\n",
    "    # Sort the laptops by score in descending order and return the top 5 products\n",
    "    top_laptops = filtered_laptops.drop('laptop_feature', axis=1)\n",
    "    top_laptops = top_laptops.sort_values('Score', ascending=False).head(3)\n",
    "    \n",
    "    return top_laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea8b72-54bc-444c-a2ef-243f77e358eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_laptops_with_user(response_dict_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "002baeee-764d-4505-8bf7-066a34abe467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_validation(recommendation):\n",
    "    # recommendation = recommendation.drop(\"Unnamed\", axis=1)\n",
    "    validated_laptops = []\n",
    "    for index, row in recommendation.iterrows():\n",
    "        if row.Score > 2:\n",
    "            validated_laptops.append(row)\n",
    "\n",
    "    df = pd.concat(validated_laptops, axis=1).transpose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff60fed-e054-4622-a413-8d050e78a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_validation(compare_laptops_with_user(response_dict_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344235ef-927b-41d5-80ab-f50980413f36",
   "metadata": {},
   "source": [
    "# Stage 3: Product Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a567ba5-2bad-4a55-82c8-081efe0b58e6",
   "metadata": {},
   "source": [
    "<img src=\"../Stage+3.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3950eda-8d31-4e40-9c46-728bc10b27ad",
   "metadata": {},
   "source": [
    "## Product Recommendation Layer\n",
    "\n",
    "Finally, we come to the product recommendation layer. It takes the output from the `compare_laptops_with_user` function in the previous layer and provides the recommendations to the user. It has the following steps.\n",
    "1. Initialize the conversation for recommendation.\n",
    "2. Generate the recommendations and display in a presentable format.\n",
    "3. Ask questions basis the recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61e12770-62e4-48c2-80a3-5a470b6087e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_conv_reco(products):\n",
    "    system_message = open(\"../Prompts/initialize_conv_reco.txt\", \"r\").read().strip().format(products=products)\n",
    "    conversation = [{\"role\": \"user\", \"parts\": [system_message] }]\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e38904-3a22-4b54-b0f4-9ab8c9d0e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_recommendation_json = json.loads(product_validation(compare_laptops_with_user(response_dict_n)).to_json(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9148e7a3-7c5c-4fd0-8da9-fc3d630da15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(map(lambda x: x[\"Description\"], debug_recommendation_json)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22ea2c-5376-4fdb-9200-318688eec0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_conversation_reco = initialize_conv_reco(debug_recommendation_json)\n",
    "debug_conversation_reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2726d7-62a8-4305-be1d-61ea3faf4b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_text = json.dumps(debug_recommendation_json, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "# json_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d6a5a2-4211-4468-a839-3750a2c855ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_conversation_reco = initialize_conv_reco(json_text)\n",
    "# debug_conversation_reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c333f63a-323c-45a6-b41c-35839c8ee680",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_system_top3_recommendation = get_chat_completions(debug_conversation_reco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7c73e-b0c8-4d9d-b4b1-6cf1a7f35188",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_conversation_reco.append({\"role\":\"model\", \"parts\":[debug_system_top3_recommendation]})\n",
    "debug_conversation_reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d47d6-0936-4b14-96fc-23b19ed5d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_conversation_reco.append({\"role\":\"user\", \"parts\":[\"Which of these is best suited for travel. Recommend only one\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e991b-8c62-40b3-8775-e21794db2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = get_chat_completions(debug_conversation_reco)\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c2b9c-a3dd-4fb3-ab80-83a4b8675ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isfile(\"updated_laptop_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98182fca-a5ee-4ea5-9ec8-5cf28a263cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_moderation(user_input):\n",
    "    return \"Not Flagged\" # moderation_check(user_input) # - Gemini does not support moderation on user input\n",
    "    \n",
    "def dialogue_mgmt_system(isDebug = False):\n",
    "\n",
    "    print(\"Initialising system, please wait....\\n\")\n",
    "\n",
    "    if os.path.isfile(\"../updated_laptop_data.csv\") == False:\n",
    "        update_laptop_csv_with_feature()\n",
    "\n",
    "    print(\"System is ready \\n\")\n",
    "    \n",
    "    conversation = initialize_conversation()\n",
    "    print(\"--\"*20 + \"Shop Assitant\" + \"--\"*20)\n",
    "    print(\"\"\"\n",
    "    Hello, I am your laptop assistant. Please feel free to ask me about laptop recommendations. \\n\n",
    "    You can tell me about your needs like \\n\n",
    "    - what is the purpose of the laptop\n",
    "    - Do you need heavy processing laptop\n",
    "    - Do you need it for travel purposes, etc\n",
    "\n",
    "    Please note: I do not take inputs to talk to about any specific brand as I am suppose to be non-biased. \n",
    "    Once I find a good recommendatio for you, then you can ask me about that laptop.\\n\n",
    "    Let's start!!!\n",
    "    \"\"\" + '\\n')\n",
    "    top_3_laptops = None\n",
    "    user_input = ''\n",
    "\n",
    "\n",
    "    while(user_input != \"exit\"):\n",
    "        print(\"--\"*20 + \"User\" + \"--\"*20)\n",
    "        user_input = input(\"\")\n",
    "\n",
    "        \n",
    "        if check_moderation(user_input) == 'Flagged':\n",
    "            print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
    "            break\n",
    "\n",
    "\n",
    "        if top_3_laptops is None:\n",
    "            conversation.append({\"role\": \"user\", \"parts\": [user_input]})\n",
    "\n",
    "\n",
    "            response_assistant = get_chat_completions(conversation)\n",
    "\n",
    "            if check_moderation(user_input) == 'Flagged':\n",
    "                print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
    "                break\n",
    "\n",
    "            confirmation = intent_confirmation_layer(response_assistant)\n",
    "\n",
    "            if check_moderation(user_input) == 'Flagged':\n",
    "                print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
    "                break\n",
    "\n",
    "\n",
    "            if \"No\".lower() in json.dumps(confirmation, sort_keys=True, indent=4, separators=(',', ': ')).lower():\n",
    "                conversation.append({\"role\": \"model\", \"parts\": [response_assistant]})\n",
    "                print(\"--\"*20 + \"Shop Assitant\" + \"--\"*20)\n",
    "                print(f\"\\n{response_assistant}\\n\")\n",
    "                \n",
    "                if isDebug:\n",
    "                    print(f\"\\n{confirmation}\\n\")\n",
    "            else:\n",
    "                print(\"--\"*20 + \"Shop Assitant\" + \"--\"*20)\n",
    "                print(f\"\\n{response_assistant}\\n\")\n",
    "                \n",
    "                if isDebug:\n",
    "                    print(f\"\\n{confirmation}\\n\")\n",
    "                    \n",
    "                response = dictionary_present(response_assistant)\n",
    "\n",
    "                if check_moderation(user_input) == 'Flagged':\n",
    "                    print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                print(\"--\"*20 + \"Shop Assitant\" + \"--\"*20)\n",
    "                \n",
    "                if isDebug:\n",
    "                    print(f'\\n{response}\\n')\n",
    "                    \n",
    "                print(\"Thank you for providing all the information. Kindly wait, while I fetch the products: \\n\")\n",
    "                top_3_laptops = compare_laptops_with_user(response)\n",
    "\n",
    "\n",
    "                validated_reco = product_validation(top_3_laptops)\n",
    "\n",
    "\n",
    "                if len(validated_reco) == 0:\n",
    "                    print(\"Sorry, we do not have laptops that match your requirements. Connecting you to a human expert.\")\n",
    "                    break\n",
    "\n",
    "\n",
    "                conversation_reco = initialize_conv_reco(validated_reco)\n",
    "                recommendation = get_chat_completions(conversation_reco)\n",
    "\n",
    "\n",
    "                if check_moderation(user_input) == 'Flagged':\n",
    "                    print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
    "                    break\n",
    "\n",
    "\n",
    "                conversation_reco.append({\"role\": \"user\", \"parts\": [f\"This is my user profile {response}\"]})\n",
    "\n",
    "\n",
    "                conversation_reco.append({\"role\": \"model\", \"parts\": [recommendation]})\n",
    "\n",
    "\n",
    "                print(\"--\"*20 + \"Shop Assitant\" + \"--\"*20)\n",
    "                print(f'{recommendation}\\n')\n",
    "\n",
    "\n",
    "        else:\n",
    "            conversation_reco.append({\"role\": \"user\", \"parts\": [user_input]})\n",
    "\n",
    "\n",
    "            response_asst_reco = get_chat_completions(conversation_reco)\n",
    "\n",
    "            if check_moderation(user_input) == 'Flagged':\n",
    "                print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
    "                break\n",
    "\n",
    "            print(\"--\"*20 + \"Shop Assitant\" + \"--\"*20)\n",
    "            print(f'\\n{response_asst_reco}\\n')\n",
    "            conversation.append({\"role\": \"model\", \"parts\": [response_asst_reco]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4dbcf-74a5-4800-b82f-4727c606b642",
   "metadata": {},
   "source": [
    "# Run Simulation in Debug Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb4f610c-ef9d-495d-9512-aaa252840688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising system, please wait....\n",
      "\n",
      "System is ready \n",
      "\n",
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "    Hello, I am your laptop assistant. Please feel free to ask me about laptop recommendations. \n",
      "\n",
      "    You can tell me about your needs like \n",
      "\n",
      "    - what is the purpose of the laptop\n",
      "    - Do you need heavy processing laptop\n",
      "    - Do you need it for travel purposes, etc\n",
      "\n",
      "    Please note: I do not take inputs to talk to about any specific brand as I am suppose to be non-biased. \n",
      "    Once I find a good recommendatio for you, then you can ask me about that laptop.\n",
      "\n",
      "    Let's start!!!\n",
      "    \n",
      "\n",
      "----------------------------------------User----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Hi, this is Mohit Dubey and I am looking for a coding laptop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "Hi Mohit! That's great!  Coding laptops can be quite versatile. To help me find the perfect one for you, could you tell me a bit more about your coding needs?  For example, what kind of coding do you do?  Do you work with large datasets, complex software, or primarily web development?  Knowing this will help me understand your requirements for processing power, storage, and other features. \n",
      "\n",
      "\n",
      "\n",
      "{'result': 'No', 'reason': 'Missing keys'}\n",
      "\n",
      "----------------------------------------User----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I will working on Machine Learning, Deep Learning and NLPs and models I will run locally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "Okay, that's helpful!  So you'll be doing a lot of computationally intensive work with Machine Learning, Deep Learning, and NLPs.  This means you'll need a laptop with strong processing power and a dedicated GPU.  \n",
      "\n",
      "To make sure I can find the best fit for you, could you tell me your budget for the laptop?  Knowing this will help me narrow down the options and find something that meets your needs without breaking the bank. \n",
      "\n",
      "\n",
      "\n",
      "{'result': 'No', 'reason': 'Budget is not provided'}\n",
      "\n",
      "----------------------------------------User----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Something less than 2.5 lacs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "Okay, I understand.  Unfortunately, finding a laptop that can handle the demands of Machine Learning, Deep Learning, and NLPs within a budget of 2.5 lacs INR might be challenging.  These tasks require powerful processors and dedicated GPUs, which often come at a higher price point. \n",
      "\n",
      "To give you the best possible recommendations, could you tell me if you're open to considering a slightly higher budget?  If not, we can explore some options that might be suitable for lighter workloads or consider alternative solutions like cloud computing. \n",
      "\n",
      "\n",
      "\n",
      "{'result': 'No', 'reason': 'Missing keys'}\n",
      "\n",
      "----------------------------------------User----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Yes, I am fine with higher budget\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "Great!  That opens up a lot more possibilities.  Since you'll be doing a lot of demanding work with Machine Learning, Deep Learning, and NLPs, I'd recommend a laptop with a powerful processor and a dedicated GPU.  \n",
      "\n",
      "To make sure I can find the perfect fit for you, could you tell me your maximum budget?  Knowing this will help me narrow down the options and find something that meets your needs without breaking the bank. \n",
      "\n",
      "\n",
      "\n",
      "{'result': 'No', 'reason': 'Budget is not provided'}\n",
      "\n",
      "----------------------------------------User----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 3 lacs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "Okay, that's a great budget to work with!  With 3 lacs, we can definitely find a laptop that can handle your Machine Learning, Deep Learning, and NLP workloads.  \n",
      "\n",
      "To make sure I can find the perfect fit for you, I have a few more questions:\n",
      "\n",
      "1. **How important is portability to you?**  Do you need a laptop that's lightweight and easy to carry around, or will you primarily be using it at a desk?\n",
      "2. **How important is display quality to you?**  Do you need a high-resolution display with vibrant colors, or is a standard display sufficient?\n",
      "\n",
      "Knowing this will help me narrow down the options and find a laptop that meets your needs and preferences. \n",
      "\n",
      "\n",
      "\n",
      "{'result': 'No', 'reason': 'Missing keys'}\n",
      "\n",
      "----------------------------------------User----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Portability and display is not a priority\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "Okay, that's helpful!  Since portability and display quality aren't a priority, we can focus on finding a laptop with the best possible performance for your Machine Learning, Deep Learning, and NLP workloads. \n",
      "\n",
      "Based on our conversation, here's what I've gathered about your needs:\n",
      "\n",
      "* **GPU Intensity:** High (You'll be doing a lot of demanding work with Machine Learning, Deep Learning, and NLPs)\n",
      "* **Display Quality:** Medium (Not a priority)\n",
      "* **Portability:** Low (Not a priority)\n",
      "* **Multitasking:** High (You'll likely be running multiple programs and processes simultaneously)\n",
      "* **Processing Speed:** High (You'll need a powerful processor to handle your workloads)\n",
      "* **Budget:** 300000 INR\n",
      "\n",
      "I'm confident that with this information, I can find you a great laptop that meets your needs.  Do you have any other preferences or requirements I should be aware of? \n",
      "\n",
      "\n",
      "\n",
      "{'result': 'Yes'}\n",
      "\n",
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "{'GPU intensity': 'high', 'Display quality': 'medium', 'Portability': 'low', 'Multitasking': 'high', 'Processing speed': 'high', 'Budget': '300000'}\n",
      "\n",
      "Thank you for providing all the information. Kindly wait, while I fetch the products: \n",
      "\n",
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "Here is the recommendation:\n",
      "\n",
      "1. **Dell Precision 5550**: Xeon processor, 32GB RAM, 15.6\" OLED display, NVIDIA Quadro graphics, Ubuntu OS, 1.83 kg, 6 hours battery life, Rs. 250000\n",
      "2. **ASUS ZenBook Pro**: i9 processor, 64GB RAM, 15.6\" OLED display, NVIDIA RTX graphics, Windows 10 OS, 1.8 kg, 7 hours battery life, Rs. 200000\n",
      "3. **Dell XPS 15**: i9 processor, 32GB RAM, 15.6\" OLED display, NVIDIA GTX graphics, Windows 11 OS, 1.8 kg, 8 hours battery life, Rs. 180000 \n",
      "\n",
      "\n",
      "----------------------------------------User----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Which one is best suited for me. Suggest only one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "Based on your profile, the **Dell Precision 5550** is the best suited for you. \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **High GPU intensity:** The Dell Precision 5550 boasts a powerful NVIDIA Quadro graphics card, ideal for demanding tasks like video editing, 3D rendering, and gaming.\n",
      "* **High Multitasking:** With a Xeon processor and 32GB RAM, this laptop can handle multiple demanding applications simultaneously without breaking a sweat.\n",
      "* **High Processing Speed:** The Xeon processor ensures lightning-fast performance for even the most complex tasks.\n",
      "* **Budget:** While it's the most expensive option, it falls within your budget of Rs. 300,000.\n",
      "\n",
      "While the other laptops offer great features, the Dell Precision 5550 excels in the areas you prioritize: GPU intensity, multitasking, and processing speed. \n",
      "\n",
      "\n",
      "----------------------------------------User----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "Based on your profile, the **Dell Precision 5550** is the best suited for you. \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **High GPU intensity:** The Dell Precision 5550 boasts a powerful NVIDIA Quadro graphics card, ideal for demanding tasks like video editing, 3D modeling, and gaming.\n",
      "* **High Multitasking:** With 32GB of RAM and a Xeon processor, this laptop can handle multiple demanding applications simultaneously without slowing down.\n",
      "* **High Processing Speed:** The Xeon processor ensures lightning-fast performance for even the most complex tasks.\n",
      "* **Medium Display Quality:** The 15.6\" OLED display offers vibrant colors and deep blacks, meeting your medium display quality preference.\n",
      "* **Low Portability:** While not the lightest, the 1.83 kg weight is manageable for occasional movement.\n",
      "* **Budget:** The Dell Precision 5550 fits within your budget of Rs. 300,000.\n",
      "\n",
      "While the ASUS ZenBook Pro also offers high performance, the Dell Precision 5550 edges it out with its dedicated workstation-grade graphics card, making it a better choice for your specific needs. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogue_mgmt_system(isDebug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a6535-a9a9-4526-b317-3c5a19ad9891",
   "metadata": {},
   "source": [
    "# Run Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31802369-9aa0-4b93-b449-dd79dea9763c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising system, please wait....\n",
      "\n",
      "System is ready \n",
      "\n",
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "    Hello, I am your laptop assistant. Please feel free to ask me about laptop recommendations. \n",
      "\n",
      "    You can tell me about your needs like \n",
      "\n",
      "    - what is the purpose of the laptop\n",
      "    - Do you need heavy processing laptop\n",
      "    - Do you need it for travel purposes, etc\n",
      "\n",
      "    Please note: I do not take inputs to talk to about any specific brand as I am suppose to be non-biased. \n",
      "    Once I find a good recommendatio for you, then you can ask me about that laptop.\n",
      "\n",
      "    Let's start!!!\n",
      "    \n",
      "\n",
      "----------------------------------------User----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Hi, this is Mohit Dubey and I am looking for a coding laptop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "Hi Mohit! That's great!  Coding laptops can be quite versatile. To help me find the perfect one for you, could you tell me a bit more about your coding needs?  For example, what kind of coding do you do?  Do you work with large datasets, complex software, or primarily web development?  Knowing this will help me understand your requirements for processing power, storage, and other features. \n",
      "\n",
      "\n",
      "----------------------------------------User----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I will working on Machine Learning, Deep Learning and NLPs and models I will run locally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "Okay, that's helpful!  So you'll be doing a lot of computationally intensive work with Machine Learning, Deep Learning, and NLPs.  This means you'll need a laptop with strong processing power and a dedicated GPU.  \n",
      "\n",
      "To make sure I can find the best fit for you, could you tell me your budget for this laptop?  Knowing your budget will help me narrow down the options and find something that meets your needs without breaking the bank. \n",
      "\n",
      "\n",
      "----------------------------------------User----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Something less than 2.5 lacs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "{'GPU intensity': 'high', 'Display quality': 'medium', 'Portability': 'medium', 'Multitasking': 'high', 'Processing speed': 'high', 'Budget': '250000'} \n",
      "\n",
      "\n",
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "Thank you for providing all the information. Kindly wait, while I fetch the products: \n",
      "\n",
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "Here is the recommendation:\n",
      "\n",
      "1. **ASUS ZenBook Pro**: i9 Intel CPU, 3.1 GHz, 64GB RAM, SSD, NVIDIA RTX Graphics, 15.6\" OLED Display, 3840x2160 Resolution, Windows 10, 2 years warranty, 7 hours battery life, Rs. 200000\n",
      "2. **Dell Precision 5550**: Xeon Intel CPU, 2.6 GHz, 32GB RAM, SSD, NVIDIA Quadro Graphics, 15.6\" OLED Display, 3840x2160 Resolution, Ubuntu, 3 years warranty, 6 hours battery life, Rs. 250000\n",
      "3. **Dell XPS 15**: i9 Intel CPU, 2.8 GHz, 32GB RAM, SSD, NVIDIA GTX Graphics, 15.6\" OLED Display, 3840x2160 Resolution, Windows 11, 3 years warranty, 8 hours battery life, Rs. 180000 \n",
      "\n",
      "\n",
      "----------------------------------------User----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Which one is best suited?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "Based on your profile, the **ASUS ZenBook Pro** seems like the best fit. Here's why:\n",
      "\n",
      "* **High GPU intensity:** The ZenBook Pro boasts an NVIDIA RTX graphics card, which is ideal for demanding tasks like gaming and video editing. \n",
      "* **High Multitasking:** With 64GB of RAM, the ZenBook Pro can handle multiple applications and programs simultaneously without any lag.\n",
      "* **High Processing Speed:** The i9 Intel CPU with a 3.1 GHz clock speed ensures lightning-fast performance for all your tasks.\n",
      "* **Medium Portability:** The ZenBook Pro is a 15.6\" laptop, making it suitable for carrying around, although it's not the lightest option.\n",
      "* **Medium Display Quality:** The OLED display offers excellent color accuracy and contrast, meeting your medium display quality requirement.\n",
      "* **Budget:** The ZenBook Pro fits comfortably within your budget of Rs. 250,000.\n",
      "\n",
      "While the Dell Precision 5550 also offers high performance, its higher price and Ubuntu operating system might not be ideal for your needs. The Dell XPS 15, while a great option, falls short in terms of GPU power compared to the ZenBook Pro. \n",
      "\n",
      "\n",
      "----------------------------------------User----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Shop Assitant----------------------------------------\n",
      "\n",
      "Okay, I understand.  Let me know if you have any other questions. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogue_mgmt_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2590575c-ad48-46c4-8cd3-698d35534cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
